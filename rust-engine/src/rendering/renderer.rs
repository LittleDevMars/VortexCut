// ë Œë”ë§ ì—”ì§„ - Timelineì„ ì‹¤ì œ í”„ë ˆì„ìœ¼ë¡œ ë Œë”ë§

use crate::timeline::{Timeline, VideoClip};
use crate::ffmpeg::{Decoder, Frame as DecoderFrame};
use std::collections::HashMap;
use std::sync::{Arc, Mutex};

/// ë Œë”ë§ëœ í”„ë ˆì„ ë°ì´í„°
pub struct RenderedFrame {
    pub width: u32,
    pub height: u32,
    pub data: Vec<u8>, // RGBA í¬ë§·
    pub timestamp_ms: i64,
}

/// ë¹„ë””ì˜¤ ë Œë”ëŸ¬
pub struct Renderer {
    timeline: Arc<Mutex<Timeline>>,
    decoder_cache: HashMap<String, Decoder>, // íŒŒì¼ ê²½ë¡œ -> Decoder
}

impl Renderer {
    /// ìƒˆ ë Œë”ëŸ¬ ìƒì„±
    pub fn new(timeline: Arc<Mutex<Timeline>>) -> Self {
        Self {
            timeline,
            decoder_cache: HashMap::new(),
        }
    }

    /// íŠ¹ì • ì‹œê°„ì˜ í”„ë ˆì„ ë Œë”ë§ (UI ë ˆë²¨ ìŠ¤ì¼€ì¼ë§ ìµœì í™”)
    pub fn render_frame(&mut self, timestamp_ms: i64) -> Result<RenderedFrame, String> {
        // Timeline ë°ì´í„° ë³µì‚¬ (lock í•´ì œë¥¼ ìœ„í•´)
        let clips_to_render = {
            let timeline = self.timeline.lock()
                .map_err(|e| format!("Failed to lock timeline: {}", e))?;

            println!("ğŸ¬ Rust Renderer: render_frame(timestamp_ms={})", timestamp_ms);
            println!("   Timeline: {}x{}, video_tracks={}", timeline.width, timeline.height, timeline.video_tracks.len());

            let mut clips = Vec::new();

            // ë¹„ë””ì˜¤ íŠ¸ë™ë“¤ì„ ìˆœíšŒí•˜ë©° ë Œë”ë§í•  í´ë¦½ ìˆ˜ì§‘
            for (idx, track) in timeline.video_tracks.iter().enumerate() {
                println!("   Track[{}]: enabled={}, clips={}", idx, track.enabled, track.clips.len());

                if !track.enabled {
                    continue;
                }

                // íŠ¸ë™ì˜ ëª¨ë“  í´ë¦½ ì¶œë ¥
                for clip in &track.clips {
                    println!("     Clip ID={}: start_ms={}, duration_ms={}, end_ms={}",
                        clip.id, clip.start_time_ms, clip.duration_ms, clip.end_time_ms());
                }

                // í˜„ì¬ timestampì— í•´ë‹¹í•˜ëŠ” í´ë¦½ ì°¾ê¸°
                if let Some(clip) = track.get_clip_at_time(timestamp_ms) {
                    println!("   âœ… Found clip ID={} at timestamp {}", clip.id, timestamp_ms);
                    // í´ë¦½ì˜ source timestamp ê³„ì‚°
                    if let Some(source_time_ms) = clip.timeline_to_source_time(timestamp_ms) {
                        println!("   âœ… Source time: {}", source_time_ms);
                        clips.push((clip.clone(), source_time_ms));
                    }
                } else {
                    println!("   âš ï¸ No clip found at timestamp {}", timestamp_ms);
                }
            }

            println!("   ğŸ“Š Total clips to render: {}", clips.len());

            clips
        }; // timeline lock í•´ì œ

        // í´ë¦½ì´ ì—†ìœ¼ë©´ ê²€ì€ìƒ‰ í”„ë ˆì„ ë°˜í™˜ (960x540)
        if clips_to_render.is_empty() {
            let width = 960;
            let height = 540;
            return Ok(RenderedFrame {
                width,
                height,
                data: vec![0u8; (width * height * 4) as usize],
                timestamp_ms,
            });
        }

        // ì²« ë²ˆì§¸ í´ë¦½ ë Œë”ë§ (ìŠ¤ì¼€ì¼ë§ ì—†ì´ ë””ì½”ë” ì¶œë ¥ ê·¸ëŒ€ë¡œ ë°˜í™˜)
        let (clip, source_time_ms) = &clips_to_render[0];
        println!("   ğŸï¸ Decoding clip ID={}, source_time_ms={}", clip.id, source_time_ms);

        match self.decode_clip_frame(clip, *source_time_ms) {
            Ok(frame) => {
                println!("   âœ… Decoded frame: {}x{}, data.len()={}", frame.width, frame.height, frame.data.len());
                println!("   ğŸš€ Returning frame without scaling (UI will handle scaling)");

                // ë””ì½”ë” ì¶œë ¥ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜ (960x540 RGBA)
                Ok(RenderedFrame {
                    width: frame.width,
                    height: frame.height,
                    data: frame.data,
                    timestamp_ms,
                })
            },
            Err(e) => {
                println!("   âŒ Decode error: {}", e);
                Err(e)
            }
        }
    }

    /// í´ë¦½ì˜ í”„ë ˆì„ ë””ì½”ë”© (ìºì‹œ ì‚¬ìš©)
    fn decode_clip_frame(&mut self, clip: &VideoClip, source_time_ms: i64) -> Result<DecoderFrame, String> {
        let file_path = clip.file_path.to_string_lossy().to_string();
        println!("   ğŸ“‚ File path: {}", file_path);

        // ë””ì½”ë”ê°€ ìºì‹œì— ì—†ìœ¼ë©´ ìƒì„±
        if !self.decoder_cache.contains_key(&file_path) {
            println!("   ğŸ”§ Opening decoder for file...");
            match Decoder::open(&clip.file_path) {
                Ok(decoder) => {
                    println!("   âœ… Decoder opened: {}x{}, fps={:.2}",
                        decoder.width(), decoder.height(), decoder.fps());
                    self.decoder_cache.insert(file_path.clone(), decoder);
                }
                Err(e) => {
                    println!("   âŒ Failed to open decoder: {}", e);
                    return Err(e);
                }
            }
        } else {
            println!("   â™»ï¸ Using cached decoder");
        }

        // ë””ì½”ë”ì—ì„œ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
        println!("   ğŸ¬ Getting decoder from cache...");
        let decoder = self.decoder_cache.get_mut(&file_path)
            .ok_or("Decoder not found in cache")?;

        println!("   ğŸ¬ Calling decoder.decode_frame({})...", source_time_ms);
        let result = decoder.decode_frame(source_time_ms);

        match &result {
            Ok(frame) => println!("   âœ… decoder.decode_frame() returned OK: {}x{}", frame.width, frame.height),
            Err(e) => println!("   âŒ decoder.decode_frame() returned ERR: {}", e),
        }

        result
    }

    /// í”„ë ˆì„ì„ outputì— í•©ì„± (í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ìŠ¤ì¼€ì¼ë§)
    fn composite_frame(&self, source: &[u8], dest: &mut [u8], src_width: u32, src_height: u32, dest_width: u32, dest_height: u32) {
        println!("      ğŸ¨ composite_frame START");
        let src_size = (src_width * src_height * 4) as usize;
        let dest_size = (dest_width * dest_height * 4) as usize;

        // í¬ê¸° ê²€ì¦
        if source.len() != src_size {
            println!("   âš ï¸ Warning: Source buffer size mismatch! Expected {}, got {}", src_size, source.len());
            return;
        }
        if dest.len() != dest_size {
            println!("   âš ï¸ Warning: Dest buffer size mismatch! Expected {}, got {}", dest_size, dest.len());
            return;
        }

        if src_width == dest_width && src_height == dest_height {
            // í¬ê¸°ê°€ ê°™ìœ¼ë©´ ë‹¨ìˆœ ë³µì‚¬
            println!("      ğŸ“‹ Same size, copying directly...");
            dest.copy_from_slice(source);
            println!("   âœ… Composite: Same size, copied directly");
        } else {
            println!("   ğŸ”§ Composite: Scaling {}x{} -> {}x{} ({} pixels)",
                src_width, src_height, dest_width, dest_height, dest_width * dest_height);

            // ê°„ë‹¨í•œ ìµœê·¼ì ‘ ì´ì›ƒ ìŠ¤ì¼€ì¼ë§ (Nearest Neighbor Scaling)
            let total_pixels = dest_width * dest_height;
            let mut processed = 0u32;

            for y in 0..dest_height {
                for x in 0..dest_width {
                    let src_x = (x as f64 * src_width as f64 / dest_width as f64) as u32;
                    let src_y = (y as f64 * src_height as f64 / dest_height as f64) as u32;

                    if src_x < src_width && src_y < src_height {
                        let src_idx = ((src_y * src_width + src_x) * 4) as usize;
                        let dst_idx = ((y * dest_width + x) * 4) as usize;

                        if src_idx + 4 <= source.len() && dst_idx + 4 <= dest.len() {
                            dest[dst_idx..dst_idx + 4].copy_from_slice(&source[src_idx..src_idx + 4]);
                        }
                    }

                    processed += 1;
                    // ì§„í–‰ë¥  í‘œì‹œ (10% ë‹¨ìœ„)
                    if processed % (total_pixels / 10) == 0 {
                        let percent = (processed * 100) / total_pixels;
                        println!("      â³ Scaling progress: {}%", percent);
                    }
                }
            }
            println!("   âœ… Composite: Scaling completed");
        }
        println!("      ğŸ¨ composite_frame END");
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;

    #[test]
    fn test_renderer_create() {
        let timeline = Arc::new(Mutex::new(Timeline::new(1920, 1080, 30.0)));
        let _renderer = Renderer::new(timeline);
    }

    #[test]
    fn test_renderer_with_real_video() {
        let video_path = PathBuf::from(r"C:\Users\USER\Videos\ë“œë¡  ëŒ€ì‘ 2.75ì¸ì¹˜ ë¡œì¼“ 'ë¹„ê¶'ìœ¼ë¡œ ìœ ë„í‚¤íŠ¸ ê°œë°œ, ì‚¬ìš°ë”” ê¸°ìˆ í˜‘ë ¥ ì¶”ì§„.mp4");

        if !video_path.exists() {
            println!("âš ï¸ Test video file not found, skipping test");
            return;
        }

        println!("\n=== Renderer Test ===");

        // 1. Timeline ìƒì„±
        let timeline = Arc::new(Mutex::new(Timeline::new(1920, 1080, 30.0)));

        // 2. ë¹„ë””ì˜¤ íŠ¸ë™ ì¶”ê°€
        let track_id = {
            let mut tl = timeline.lock().unwrap();
            tl.add_video_track()
        };
        println!("âœ… Video track created: ID={}", track_id);

        // 3. í´ë¦½ ì¶”ê°€
        let clip_id = {
            let mut tl = timeline.lock().unwrap();
            tl.add_video_clip(track_id, video_path.clone(), 0, 5000)
                .expect("Failed to add video clip")
        };
        println!("âœ… Video clip added: ID={}", clip_id);

        // 4. Renderer ìƒì„±
        let mut renderer = Renderer::new(timeline.clone());
        println!("âœ… Renderer created");

        // 5. í”„ë ˆì„ ë Œë”ë§ í…ŒìŠ¤íŠ¸
        let timestamps = [0i64, 1000, 2000];
        for timestamp in timestamps {
            println!("\nğŸ¬ Rendering frame at {}ms...", timestamp);
            match renderer.render_frame(timestamp) {
                Ok(frame) => {
                    println!("   âœ… Frame rendered: {}x{}", frame.width, frame.height);
                    println!("   Data size: {} bytes", frame.data.len());

                    // ê²€ì¦
                    assert_eq!(frame.width, 1920);
                    assert_eq!(frame.height, 1080);
                    assert_eq!(frame.data.len(), (1920 * 1080 * 4) as usize);

                    // ì²« 10í”½ì…€ í™•ì¸
                    let pixels: Vec<u8> = frame.data.iter().take(40).copied().collect();
                    println!("   First 10 pixels (RGBA): {:?}", pixels);
                }
                Err(e) => {
                    panic!("âŒ Failed to render frame at {}ms: {}", timestamp, e);
                }
            }
        }

        println!("\nâœ… All renderer tests passed!");
    }
}
